{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frozen_lake_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdI5WHRUiO9XOF3Ur2o4gT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-washi/python-cookbook/blob/master/ml/2/frozen_lake_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bpaij8IDIy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b8f1ab3a-aea0-4d7c-97c6-c6ef6f8d54ce"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rAqXIj_C8pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import gym\n",
        "import gym.spaces\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "PERCENTILE = 30\n",
        "GAMMA = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0xb9XhcDFvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscreteOneHotWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(DiscreteOneHotWrapper, self).__init__(env)\n",
        "        assert isinstance(env.observation_space,\n",
        "                          gym.spaces.Discrete)\n",
        "        shape = (env.observation_space.n, )\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            0.0, 1.0, shape, dtype=np.float32)\n",
        "    def observation(self, observation):\n",
        "        res = np.copy(self.observation_space.low)\n",
        "        res[observation] = 1.0\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9v4LW7GDVJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, obs_size, hidden_size, n_actions):\n",
        "        super(Net, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
        "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwHuwwXUERUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterate_batches(env, net, batch_size):\n",
        "    batch = []\n",
        "    episode_reward = 0.0\n",
        "    episode_steps = []\n",
        "    obs = env.reset()\n",
        "    sm = nn.Softmax(dim=1)\n",
        "    while True:\n",
        "        obs_v = torch.FloatTensor([obs])\n",
        "        act_probs_v = sm(net(obs_v))\n",
        "        act_probs = act_probs_v.data.numpy()[0]\n",
        "        action = np.random.choice(len(act_probs), p=act_probs)\n",
        "        next_obs, reward, is_done, _ = env.step(action)\n",
        "        episode_reward += reward\n",
        "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
        "        if is_done:\n",
        "            batch.append(Episode(reward=episode_reward, steps=episode_steps))\n",
        "            episode_reward = 0.0\n",
        "            episode_steps = []\n",
        "            next_obs = env.reset()\n",
        "            if len(batch) == batch_size:\n",
        "                yield batch\n",
        "                batch = []\n",
        "        obs = next_obs\n",
        "\n",
        "\n",
        "def filter_batch(batch, percentile):\n",
        "    filter_fun = lambda s: s.reward * (GAMMA ** len(s.steps))\n",
        "    disc_rewards = list(map(filter_fun, batch))\n",
        "    reward_bound = np.percentile(disc_rewards, percentile)\n",
        "    train_obs = []\n",
        "    train_act = []\n",
        "    elite_batch = []\n",
        "    for example, discounted_reward in zip(batch, disc_rewards):\n",
        "        if discounted_reward > reward_bound:\n",
        "            train_obs.extend(map(lambda step: step.observation,\n",
        "                                 example.steps))\n",
        "            train_act.extend(map(lambda step: step.action,\n",
        "                                 example.steps))\n",
        "            elite_batch.append(example)\n",
        "    return elite_batch, train_obs, train_act, reward_bound\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ZbbEseEYtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b8b5aee-d7e9-4118-a8cc-6ab872f345e5"
      },
      "source": [
        "    random.seed(12345)\n",
        "    env = DiscreteOneHotWrapper(gym.make(\"FrozenLake-v0\"))\n",
        "    # env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
        "    obs_size = env.observation_space.shape[0]\n",
        "    n_actions = env.action_space.n\n",
        "\n",
        "    net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
        "    objective = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(params=net.parameters(), lr=0.001)\n",
        "    writer = SummaryWriter(comment=\"-frozenlake-tweaked\")\n",
        "\n",
        "    full_batch = []\n",
        "    for iter_no, batch in enumerate(iterate_batches(\n",
        "            env, net, BATCH_SIZE)):\n",
        "        reward_mean = float(np.mean(list(map(\n",
        "            lambda s: s.reward, batch))))\n",
        "        full_batch, obs, acts, reward_bound = \\\n",
        "            filter_batch(full_batch + batch, PERCENTILE)\n",
        "        if not full_batch:\n",
        "            continue\n",
        "        obs_v = torch.FloatTensor(obs)\n",
        "        acts_v = torch.LongTensor(acts)\n",
        "        full_batch = full_batch[-500:]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        action_scores_v = net(obs_v)\n",
        "        loss_v = objective(action_scores_v, acts_v)\n",
        "        loss_v.backward()\n",
        "        optimizer.step()\n",
        "        print(\"%d: loss=%.3f, rw_mean=%.3f, \"\n",
        "              \"rw_bound=%.3f, batch=%d\" % (\n",
        "            iter_no, loss_v.item(), reward_mean,\n",
        "            reward_bound, len(full_batch)))\n",
        "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
        "        writer.add_scalar(\"reward_mean\", reward_mean, iter_no)\n",
        "        writer.add_scalar(\"reward_bound\", reward_bound, iter_no)\n",
        "        if reward_mean > 0.8:\n",
        "            print(\"Solved!\")\n",
        "            break\n",
        "    writer.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6150: loss=0.000, rw_mean=0.125, rw_bound=0.101, batch=34\n",
            "6151: loss=0.000, rw_mean=0.125, rw_bound=0.200, batch=35\n",
            "6152: loss=0.000, rw_mean=0.188, rw_bound=0.206, batch=35\n",
            "6153: loss=0.000, rw_mean=0.125, rw_bound=0.349, batch=34\n",
            "6154: loss=0.000, rw_mean=0.188, rw_bound=0.306, batch=35\n",
            "6155: loss=0.000, rw_mean=0.125, rw_bound=0.349, batch=35\n",
            "6156: loss=0.000, rw_mean=0.188, rw_bound=0.314, batch=35\n",
            "6157: loss=0.000, rw_mean=0.188, rw_bound=0.387, batch=27\n",
            "6158: loss=0.000, rw_mean=0.188, rw_bound=0.232, batch=30\n",
            "6159: loss=0.000, rw_mean=0.188, rw_bound=0.164, batch=32\n",
            "6160: loss=0.000, rw_mean=0.062, rw_bound=0.003, batch=33\n",
            "6161: loss=0.000, rw_mean=0.312, rw_bound=0.239, batch=34\n",
            "6162: loss=0.000, rw_mean=0.125, rw_bound=0.173, batch=35\n",
            "6163: loss=0.000, rw_mean=0.125, rw_bound=0.229, batch=34\n",
            "6164: loss=0.000, rw_mean=0.062, rw_bound=0.178, batch=35\n",
            "6165: loss=0.000, rw_mean=0.000, rw_bound=0.000, batch=35\n",
            "6166: loss=0.000, rw_mean=0.125, rw_bound=0.254, batch=35\n",
            "6167: loss=0.000, rw_mean=0.125, rw_bound=0.167, batch=35\n",
            "6168: loss=0.000, rw_mean=0.062, rw_bound=0.314, batch=34\n",
            "6169: loss=0.000, rw_mean=0.062, rw_bound=0.160, batch=35\n",
            "6170: loss=0.000, rw_mean=0.000, rw_bound=0.000, batch=35\n",
            "6171: loss=0.000, rw_mean=0.125, rw_bound=0.229, batch=35\n",
            "6172: loss=0.000, rw_mean=0.188, rw_bound=0.387, batch=30\n",
            "6173: loss=0.000, rw_mean=0.125, rw_bound=0.013, batch=32\n",
            "6174: loss=0.000, rw_mean=0.125, rw_bound=0.036, batch=33\n",
            "6175: loss=0.000, rw_mean=0.062, rw_bound=0.054, batch=34\n",
            "6176: loss=0.000, rw_mean=0.062, rw_bound=0.095, batch=35\n",
            "6177: loss=0.000, rw_mean=0.125, rw_bound=0.185, batch=35\n",
            "6178: loss=0.000, rw_mean=0.250, rw_bound=0.282, batch=35\n",
            "6179: loss=0.000, rw_mean=0.188, rw_bound=0.314, batch=33\n",
            "6180: loss=0.000, rw_mean=0.125, rw_bound=0.190, batch=34\n",
            "6181: loss=0.000, rw_mean=0.062, rw_bound=0.117, batch=35\n",
            "6182: loss=0.000, rw_mean=0.062, rw_bound=0.080, batch=35\n",
            "6183: loss=0.000, rw_mean=0.250, rw_bound=0.254, batch=34\n",
            "6184: loss=0.000, rw_mean=0.062, rw_bound=0.050, batch=35\n",
            "6185: loss=0.000, rw_mean=0.250, rw_bound=0.387, batch=33\n",
            "6186: loss=0.000, rw_mean=0.062, rw_bound=0.049, batch=34\n",
            "6187: loss=0.000, rw_mean=0.125, rw_bound=0.101, batch=35\n",
            "6188: loss=0.000, rw_mean=0.125, rw_bound=0.122, batch=35\n",
            "6189: loss=0.000, rw_mean=0.062, rw_bound=0.109, batch=35\n",
            "6190: loss=0.000, rw_mean=0.000, rw_bound=0.000, batch=35\n",
            "6191: loss=0.000, rw_mean=0.000, rw_bound=0.000, batch=35\n",
            "6192: loss=0.000, rw_mean=0.062, rw_bound=0.098, batch=35\n",
            "6193: loss=0.000, rw_mean=0.188, rw_bound=0.229, batch=35\n",
            "6194: loss=0.000, rw_mean=0.250, rw_bound=0.314, batch=35\n",
            "6195: loss=0.000, rw_mean=0.188, rw_bound=0.430, batch=19\n",
            "6196: loss=0.000, rw_mean=0.125, rw_bound=0.000, batch=21\n",
            "6197: loss=0.000, rw_mean=0.000, rw_bound=0.000, batch=21\n",
            "6198: loss=0.000, rw_mean=0.000, rw_bound=0.000, batch=21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5703e2bfbf6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfull_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m for iter_no, batch in enumerate(iterate_batches(\n\u001b[0;32m---> 14\u001b[0;31m         env, net, BATCH_SIZE)):\n\u001b[0m\u001b[1;32m     15\u001b[0m     reward_mean = float(np.mean(list(map(\n\u001b[1;32m     16\u001b[0m         lambda s: s.reward, batch))))\n",
            "\u001b[0;32m<ipython-input-15-beebea9ec8b5>\u001b[0m in \u001b[0;36miterate_batches\u001b[0;34m(env, net, batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mact_probs_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mact_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_probs_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}